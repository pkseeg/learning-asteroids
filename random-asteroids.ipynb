{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "\n",
    "import gym\n",
    "from gym import wrappers, logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideas\n",
    "I believe the main idea is just to learn a mapping from an observation to an action. \n",
    "If I'm going focus solely on Asteroids, why not just learn a direct mapping from the (210,160,3) np array to a (1,14) np array? Is that too easy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent(object):\n",
    "    \"\"\"The world's simplest agent!\"\"\"\n",
    "    def __init__(self, action_space):\n",
    "        self.action_space = action_space\n",
    "\n",
    "    def act(self, observation, reward, done):\n",
    "        # done is a bool, whether game is done or not\n",
    "        \n",
    "        #print(reward)\n",
    "        # reward is a float, it returns positive every time you earn points \n",
    "        # (not if you HAVE them, but if you EARN them)\n",
    "        # I believe it is the score of the game\n",
    "        \n",
    "        #print(observation)\n",
    "        #print(observation.shape)\n",
    "        # observation is a 3D (210, 160, 3) numpy array describing pixels\n",
    "        \n",
    "        \n",
    "        #print(self.action_space.n)\n",
    "        #print(self.action_space.contains(13))\n",
    "        # action_space contains actions from 0 to 13\n",
    "        # As far as I can tell..\n",
    "        # 0 does nothing - I believe 0 shoots, actually\n",
    "        # 1 does nothing - same as 0, it shoots\n",
    "        # 2 thrusts forward\n",
    "        # 3 spins (not sure which way)\n",
    "        # 4 spins (probably the other way)\n",
    "        # 5 makes it move somehow\n",
    "        # 6 kinda thrusts and spins at the same time\n",
    "        # 7 same as 6 but backward\n",
    "        # 8 thrusts - looks like 2\n",
    "        # 9 spins\n",
    "        # 10 spins\n",
    "        # 11 looks like 5\n",
    "        # 12 spins and drifts\n",
    "        # 13 spins and drifts\n",
    "        \n",
    "        return self.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Asteroids-v0')\n",
    "outdir = '/results/random-agent-results'\n",
    "# env = wrappers.Monitor(env, directory=outdir, force=True)\n",
    "env.seed(0)\n",
    "agent = RandomAgent(env.action_space)\n",
    "\n",
    "episode_count = 1\n",
    "reward = 0\n",
    "done = False\n",
    "\n",
    "for i in range(episode_count):\n",
    "    ob = env.reset()\n",
    "    while True:\n",
    "        action = agent.act(ob, reward, done)\n",
    "        env.render()\n",
    "        ob, reward, done, _ = env.step(action)\n",
    "        if done:\n",
    "            break\n",
    "        # Note there's no env.render() here. But the environment still can open window and\n",
    "        # render if asked by env.monitor: it calls env.render('rgb_array') to record video.\n",
    "        # Video is not recorded every episode, see capped_cubic_video_schedule for details.\n",
    "\n",
    "# Close the env and write monitor result info to disk\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
